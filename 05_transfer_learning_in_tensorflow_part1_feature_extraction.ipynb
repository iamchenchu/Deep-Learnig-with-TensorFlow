{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMxdwq0tN59RzP5jr95L3cQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamchenchu/Deep-Learnig-with-TensorFlow/blob/main/05_transfer_learning_in_tensorflow_part1_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with TensorFlow Part 1 : Feature Extraction\n",
        "\n",
        "Transfer Learning is leveraging a working model's existing architecture and learned patterns for our own problem.\n",
        "**There are two main benefits :**\n",
        "\n",
        "1. Can leverage an existing neural network architechture proven to work on probelms similar to our own.\n",
        "2. Can leverage a working neural network architecture which has already learned patterns on similar data to our own, then we can adapt those patterns to our own data.\n"
      ],
      "metadata": {
        "id": "bAkCjpp0b13O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Are we using a GPU\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT43zZUFc5f_",
        "outputId": "86850f7d-416b-4ac9-9234-c16c3306be76"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 19 17:06:21 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0              41W / 300W |    820MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading and becoming one with the data\n"
      ],
      "metadata": {
        "id": "6U4bfTfniHal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data (10% of 10 food classes from food101)\n",
        "\n",
        "import zipfile\n",
        "\n",
        "#download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "#unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n"
      ],
      "metadata": {
        "id": "KFW3dPbqeEvE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc697a67-7748-4139-e7e5-01572c8d4f11"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-19 17:06:22--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.18.207, 142.250.145.207, 74.125.128.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.18.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip.1’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  35.4MB/s    in 4.5s    \n",
            "\n",
            "2023-12-19 17:06:26 (35.6 MB/s) - ‘10_food_classes_10_percent.zip.1’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images in each folder ?\n",
        "import os\n",
        "\n",
        "#walk through 10 percent data directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZO4aZCYjsPJ",
        "outputId": "78bc6f57-7534-4f43-ef8d-f49389ae3552"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating data loaders (Preparing the data)\n",
        "\n",
        "We'll use the ImageDataGenerator class to load in our images in batches."
      ],
      "metadata": {
        "id": "TA-GAW7Ml44c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train\"\n",
        "test_dir = \"10_food_classes_10_percent/test\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training images\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size = IMAGE_SHAPE,\n",
        "                                                          batch_size = BATCH_SIZE,\n",
        "                                                          class_mode = \"categorical\")\n",
        "print(\"Testing images :\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size = IMAGE_SHAPE,\n",
        "                                             batch_size = BATCH_SIZE,\n",
        "                                             class_mode = \"categorical\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5DX5YV5jCV1",
        "outputId": "d99b59b8-3e39-4bcb-c6ac-ad8cb256a2ae"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing images :\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up callbacks (things to run whilst our model trains)\n",
        "\n",
        "Callbacks are extra functionality you can ass to your models to be performed during  or after training. Some of the the most popular callbacks :\n",
        "\n",
        "Call backs are a tool whichh can add helpful functionality to your models during training evaluation or interference\n",
        "\n",
        "* Tracking experiments with the TensorBoard Callback\n",
        "* Model checkpoint with the modelCheckpoint callback\n",
        "* Stopping a model from training (Before it trains too long and overfit) with the earlyStopping callback.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "twmY1fM-o6IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorBoard callback (functionized because we need to create a new one for each model)\n",
        "\n",
        "import datetime\n",
        "\n",
        "def create_tensoreboard_callback(dir_name, experiment_name) :\n",
        "  log_dir = dir_name + \"/ \" + experiment_name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
        "  print(f\"Saving TensorBoard log files to : {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n"
      ],
      "metadata": {
        "id": "GVAPJYlYnxAQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note :** You can customize the directory where your TensorBoard logs (model training metrics) get saved to whatever you like. The log_dir parameter we've created above is only one option."
      ],
      "metadata": {
        "id": "EbCvThBj5qhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating models using the tensorflow Hub\n",
        "\n",
        "In the past we've used TensorFlow to create our own models layer by layer from the scratch.\n",
        "\n",
        "Now we're going to do a similar process, except one majority of your models layers are going to come from TensorFlow Hub.\n",
        "\n",
        "We can access pretrained models on : https://tfhub.dev/\n",
        "\n",
        "Browsing the tensorflow hub page and sorting for image classification , we found the following feature vector model link:\n",
        "https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\n",
        "\n",
        "\n",
        "**TensorFLow Hub :** A place to find a plethora of pre-trained machine learning models( Ready to be applied and fine-tuned for your own problems)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AzXvZjDA62-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Resnet 50 V2 feature vector\n",
        "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
        "\n",
        "# Original: EfficientNetB0 feature vector (version 1)\n",
        "efficientnet_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\"\n",
        "\n",
        "# # New: EfficientNetB0 feature vector (version 2)\n",
        "# efficientnet_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\""
      ],
      "metadata": {
        "id": "iMd9HT695liU"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import dependencies\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "MS7hv4bYCsIf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_url, num_classes = 10):\n",
        "  \"\"\" Takes a TensorFlow Hub URL and creates a keras Sequential model with it.\n",
        "Args : model_url(str): A TensorFlow Hub feature extraction URL.\n",
        "num_classes(int): The number of output neurons in the output layer, should be equal to the number of target classes, default 10\n",
        "Returns: An uncompiled keras Sequential model with model_url as a feature extractor layer and a dense output layer with num_classes output neurons.\n",
        "\"\"\"\n",
        "\n",
        "  # Download the pre-trained model and save it as a Keras layer.\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                         trainable = False,\n",
        "                                         name = \"feature_extractor_layer\",\n",
        "                                         input_shape = IMAGE_SHAPE+(3,))\n",
        "  #Create our sequential model\n",
        "  model = tf.keras.Sequential([\n",
        "      feature_extractor_layer,\n",
        "      layers.Dense(num_classes, activation = \"softmax\", name =\"output_layer\")\n",
        "  ])\n",
        "  print(\"Model created successfully\")\n",
        "  print(\"Model summary:\")\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "wccA2w7fDR80"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating and testing ReseNet TensorFLow Hub\n",
        "\n"
      ],
      "metadata": {
        "id": "KnMazMpj9ZGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = create_model(resnet_url,\n",
        "                            num_classes=train_data_10_percent.num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMRfm2dR9ESo",
        "outputId": "c0a3d376-4b07-4c6e-fc05-46aef00edef9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model created successfully\n",
            "Model summary:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77OorpE-9yNC",
        "outputId": "699259a4-6879-4c1f-e945-a57524b3ec09"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extractor_layer (K  (None, 2048)              23564800  \n",
            " erasLayer)                                                      \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23585290 (89.97 MB)\n",
            "Trainable params: 20490 (80.04 KB)\n",
            "Non-trainable params: 23564800 (89.89 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ipv48d6b-ILm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}