{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPmY6J5Ol1SKRsunP6SGQQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamchenchu/Deep-Learnig-with-TensorFlow/blob/main/09_Natural_Language_Processing_with_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP(Naturala Language Processing) and NLU (Natural Language Understanding) :\n",
        "\n",
        "`A handful of example natural language processing (NLP) and natural language understanding (NLU) problems. These are also often referred to as sequence problems (going from one sequence to another)`\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (Could be sequences text or speech). Another common term of NLP probelems is sequence to sequence problems (seq2seq)\n",
        "\n",
        "**Let's see where do we use it : Which are reffered to as a Sequence Problems**\n",
        "\n",
        "1. MultiLabel Classification\n",
        "2. Machine Translation\n",
        "3. Text Generation\n",
        "4. Voice Assistant\n",
        "\n",
        "**Types of Sequence problems :(input to output types)**\n",
        "1. One to one  (one word translation)\n",
        "2. One to many (Image captioning, possible to have multiple captions)\n",
        "3. Many to one (Sentiment analysis maybe a youtube comment, BitCoin Price Prediction)\n",
        "4. many to many (Part-of-speech tagging in natural language processing. Each word in the input sentence may correspond to multiple possible part-of-speech tags.)\n",
        "5. many to many (DNA sequence alignment. Aligning two DNA sequences where each base in one sequence may correspond to multiple bases in the other.)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rmxLc6AgR2bv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What will we do in this section :         \n",
        "\n",
        "* Downloading and preparing the text data\n",
        "* How to prepare text data for modeling (Tokenization and embedding)\n",
        "* Setting up multiple modeling experiments with Recurrent Neural Networks (RNN)\n",
        "* Building a text feature extraction model using TensorFlow Hub\n",
        "* Finding the most wrong prediction examples\n",
        "* Using a model we've built to make predictions on the text from the wild\n",
        "\n",
        "\n",
        "\n",
        "**NLP Inputs and outputs :**\n",
        "\n",
        "`Text -> turn into numbers -> build a model -> train the model to find patterns -> use patterns (make predictions)`\n",
        "\n",
        "esource: For a great overview of NLP and the different problems within it, read the article A Simple Introduction to [Natural Language Processing](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32).\n",
        "\n"
      ],
      "metadata": {
        "id": "la_EqoazVvw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEPS  WE FOLLOW IN CREATING IN RNN / CNN FOR NLP\n",
        "\n",
        "1. Get the data ready (Turn all data into numbers as neural networks can't handle text or natural language and make sure all of your tensors are in right shape pad sequence which don't fit )\n",
        "2. Build or pick a pretrained model (to suit your problem)\n",
        "3. Fit the model to the data and make a prediction\n",
        "4. Evaluate the model\n",
        "5. Improve through Experimentation\n",
        "6. Save and reload your trained model\n",
        "\n"
      ],
      "metadata": {
        "id": "lcNQjqG-Whiq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TYPICAL ARCHITECTURE OF A RECCURENT NEURAL NETWORK\n",
        "\n",
        "**What is RNN :**  is class of Artificial Neural Networks where connections between nodes from a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behaviour.\n",
        "\n",
        "1. Input Text\n",
        "2. Input Layers\n",
        "3. Text vectorization layer\n",
        "4. Embedding (Turns mapping of text vectors to embedding matrix (representing how words relate Ex King-man+woman = queen))\n",
        "5. RNN Cells (Finds Pattern in sequence) `Ex : Simple RNN, LSTM, GRU`\n",
        "6. Hidden Activations : Adds non linearity to learned features usually use `tanh`\n",
        "7. Pooling layer : Reduces the dimensionality of the learned features usually Conv1D models `Ex : GlobalAveragePooling1D or GlobalMaxPool1D`\n",
        "8. Fully Connected layer : Further refines learned features from recurrent layers (Dense layer)\n",
        "9. Output layer (Takes learned feature and outputs them in shape of target labels) Ex : `output_shape = [number_of_classes] (Disaster or not)`\n",
        "10. Output Activation : Adds non-linearities to output layer.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "31MGB-JyZqZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check GPU"
      ],
      "metadata": {
        "id": "shD1Ajnth1EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0TmZXlahCtd",
        "outputId": "9dd2aaea-14d2-447f-872b-97a6fb68fda9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 28 03:47:05 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get helper functions"
      ],
      "metadata": {
        "id": "Jg7Vy2T3iXKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper functions Import the series of the helper functions using the below link\n",
        "\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "#Import the functions using import\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1jV0V6mh6uK",
        "outputId": "40313794-5503-43aa-9e41-7a8f64460caf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-28 03:49:58--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-28 03:49:58 (108 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the Text Dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of tweets labelled as diaster or not diaster)\n",
        "\n",
        "See the original source here :https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n"
      ],
      "metadata": {
        "id": "510sTwjDi0vX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the data\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "#Unzip the data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82bjMqWVievk",
        "outputId": "10faa3c9-85b8-499c-a001-5ec0568e749a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-28 03:53:34--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.207, 142.251.10.207, 142.251.12.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K   726KB/s    in 0.8s    \n",
            "\n",
            "2023-12-28 03:53:35 (726 KB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Becoming one with the data and visualizing a text dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "0uMBFZvCjqfA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b1rXBAmdjlvg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}